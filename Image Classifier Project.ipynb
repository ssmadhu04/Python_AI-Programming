{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing an AI application\n",
    "\n",
    "Going forward, AI algorithms will be incorporated into more and more everyday applications. For example, you might want to include an image classifier in a smart phone app. To do this, you'd use a deep learning model trained on hundreds of thousands of images as part of the overall application architecture. A large part of software development in the future will be using these types of models as common parts of applications. \n",
    "\n",
    "In this project, you'll train an image classifier to recognize different species of flowers. You can imagine using something like this in a phone app that tells you the name of the flower your camera is looking at. In practice you'd train this classifier, then export it for use in your application. We'll be using [this dataset](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html) of 102 flower categories, you can see a few examples below. \n",
    "\n",
    "<img src='assets/Flowers.png' width=500px>\n",
    "\n",
    "The project is broken down into multiple steps:\n",
    "\n",
    "* Load and preprocess the image dataset\n",
    "* Train the image classifier on your dataset\n",
    "* Use the trained classifier to predict image content\n",
    "\n",
    "We'll lead you through each part which you'll implement in Python.\n",
    "\n",
    "When you've completed this project, you'll have an application that can be trained on any set of labeled images. Here your network will be learning about flowers and end up as a command line application. But, what you do with your new skills depends on your imagination and effort in building a dataset. For example, imagine an app where you take a picture of a car, it tells you what the make and model is, then looks up information about it. Go build your own dataset and make something new.\n",
    "\n",
    "First up is importing the packages you'll need. It's good practice to keep all the imports at the beginning of your code. As you work through this notebook and find you need to import a package, make sure to add the import up here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.transforms import functional as TF\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Here you'll use `torchvision` to load the data ([documentation](http://pytorch.org/docs/0.3.0/torchvision/index.html)). The data should be included alongside this notebook, otherwise you can [download it here](https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz). The dataset is split into three parts, training, validation, and testing. For the training, you'll want to apply transformations such as random scaling, cropping, and flipping. This will help the network generalize leading to better performance. You'll also need to make sure the input data is resized to 224x224 pixels as required by the pre-trained networks.\n",
    "\n",
    "The validation and testing sets are used to measure the model's performance on data it hasn't seen yet. For this you don't want any scaling or rotation transformations, but you'll need to resize then crop the images to the appropriate size.\n",
    "\n",
    "The pre-trained networks you'll use were trained on the ImageNet dataset where each color channel was normalized separately. For all three sets you'll need to normalize the means and standard deviations of the images to what the network expects. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`, calculated from the ImageNet images.  These values will shift each color channel to be centered at 0 and range from -1 to 1.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'flowers'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define your transforms for the training, validation, and testing sets\n",
    "train_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.485, 0.485, 0.485), (0.229, 0.224, 0.225))])\n",
    "valid_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "testing_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "valid_data = datasets.ImageFolder(train_dir, transform=valid_transforms)\n",
    "test_data = datasets.ImageFolder(train_dir, transform=testing_transforms)\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=24, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_data, batch_size=24, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=24, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label mapping\n",
    "\n",
    "You'll also need to load in a mapping from category label to category name. You can find this in the file `cat_to_name.json`. It's a JSON object which you can read in with the [`json` module](https://docs.python.org/2/library/json.html). This will give you a dictionary mapping the integer encoded categories to the actual names of the flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'21': 'fire lily', '3': 'canterbury bells', '45': 'bolero deep blue', '1': 'pink primrose', '34': 'mexican aster', '27': 'prince of wales feathers', '7': 'moon orchid', '16': 'globe-flower', '25': 'grape hyacinth', '26': 'corn poppy', '79': 'toad lily', '39': 'siam tulip', '24': 'red ginger', '67': 'spring crocus', '35': 'alpine sea holly', '32': 'garden phlox', '10': 'globe thistle', '6': 'tiger lily', '93': 'ball moss', '33': 'love in the mist', '9': 'monkshood', '102': 'blackberry lily', '14': 'spear thistle', '19': 'balloon flower', '100': 'blanket flower', '13': 'king protea', '49': 'oxeye daisy', '15': 'yellow iris', '61': 'cautleya spicata', '31': 'carnation', '64': 'silverbush', '68': 'bearded iris', '63': 'black-eyed susan', '69': 'windflower', '62': 'japanese anemone', '20': 'giant white arum lily', '38': 'great masterwort', '4': 'sweet pea', '86': 'tree mallow', '101': 'trumpet creeper', '42': 'daffodil', '22': 'pincushion flower', '2': 'hard-leaved pocket orchid', '54': 'sunflower', '66': 'osteospermum', '70': 'tree poppy', '85': 'desert-rose', '99': 'bromelia', '87': 'magnolia', '5': 'english marigold', '92': 'bee balm', '28': 'stemless gentian', '97': 'mallow', '57': 'gaura', '40': 'lenten rose', '47': 'marigold', '59': 'orange dahlia', '48': 'buttercup', '55': 'pelargonium', '36': 'ruby-lipped cattleya', '91': 'hippeastrum', '29': 'artichoke', '71': 'gazania', '90': 'canna lily', '18': 'peruvian lily', '98': 'mexican petunia', '8': 'bird of paradise', '30': 'sweet william', '17': 'purple coneflower', '52': 'wild pansy', '84': 'columbine', '12': \"colt's foot\", '11': 'snapdragon', '96': 'camellia', '23': 'fritillary', '50': 'common dandelion', '44': 'poinsettia', '53': 'primula', '72': 'azalea', '65': 'californian poppy', '80': 'anthurium', '76': 'morning glory', '37': 'cape flower', '56': 'bishop of llandaff', '60': 'pink-yellow dahlia', '82': 'clematis', '58': 'geranium', '75': 'thorn apple', '41': 'barbeton daisy', '95': 'bougainvillea', '43': 'sword lily', '83': 'hibiscus', '78': 'lotus lotus', '88': 'cyclamen', '94': 'foxglove', '81': 'frangipani', '74': 'rose', '89': 'watercress', '73': 'water lily', '46': 'wallflower', '77': 'passion flower', '51': 'petunia'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "print(cat_to_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training the classifier\n",
    "\n",
    "Now that the data is ready, it's time to build and train the classifier. As usual, you should use one of the pretrained models from `torchvision.models` to get the image features. Build and train a new feed-forward classifier using those features.\n",
    "\n",
    "We're going to leave this part up to you. Refer to [the rubric](https://review.udacity.com/#!/rubrics/1663/view) for guidance on successfully completing this section. Things you'll need to do:\n",
    "\n",
    "* Load a [pre-trained network](http://pytorch.org/docs/master/torchvision/models.html) (If you need a starting point, the VGG networks work great and are straightforward to use)\n",
    "* Define a new, untrained feed-forward network as a classifier, using ReLU activations and dropout\n",
    "* Train the classifier layers using backpropagation using the pre-trained network to get the features\n",
    "* Track the loss and accuracy on the validation set to determine the best hyperparameters\n",
    "\n",
    "We've left a cell open for you below, but use as many as you need. Our advice is to break the problem up into smaller parts you can run separately. Check that each part is doing what you expect, then move on to the next. You'll likely find that as you work through each part, you'll need to go back and modify your previous code. This is totally normal!\n",
    "\n",
    "When training make sure you're updating only the weights of the feed-forward network. You should be able to get the validation accuracy above 70% if you build everything right. Make sure to try different hyperparameters (learning rate, units in the classifier, epochs, etc) to find the best model. Save those hyperparameters to use as default values in the next part of the project.\n",
    "\n",
    "One last important tip if you're using the workspace to run your code: To avoid having your workspace disconnect during the long-running tasks in this notebook, please read in the earlier page in this lesson called Intro to\n",
    "GPU Workspaces about Keeping Your Session Active. You'll want to include code from the workspace_utils.py module.\n",
    "\n",
    "<font color='red'>**Note for Workspace users:** If your network is over 1 GB when saved as a checkpoint, there might be issues with saving backups in your workspace. Typically this happens with wide dense layers after the convolutional layers. If your saved checkpoint is larger than 1 GB (you can open a terminal and check with `ls -lh`), you should reduce the size of your hidden layers and train again.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg11-bbd30ac9.pth\" to /root/.torch/models/vgg11-bbd30ac9.pth\n",
      "100%|██████████| 531456000/531456000 [00:09<00:00, 54675934.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace)\n",
      "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): ReLU(inplace)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2)\n",
      "    (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.2)\n",
      "    (6): Linear(in_features=512, out_features=102, bias=True)\n",
      "    (7): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# TODO: Build and train your network\n",
    "#Get the pre-trained neural network\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.vgg11(pretrained=True)\n",
    "\n",
    "\n",
    "\n",
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier = nn.Sequential(nn.Linear(25088, 2048),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(2048, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(512, 102),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Only train the classifier parameters, feature parameters are frozen\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.003)\n",
    "\n",
    "model.to(device);\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0      Loss:  tensor(4.6621, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(20.7416, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(14.5083, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(10.0758, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(7.4152, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.8450, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.8388, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.7685, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.6275, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.6895, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.4945, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.6764, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.4549, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.3463, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.5778, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.4074, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.4164, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.7729, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.3637, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.2008, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.2849, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.5740, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.6802, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.5128, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.2400, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.0438, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.2696, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.5434, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.5825, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.5159, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.0467, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.1411, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.6784, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.1217, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.3514, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.3858, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.0181, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.4687, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.4155, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.0201, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.1688, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.6925, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0369, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8075, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6939, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.3741, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.6730, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0501, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0965, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.0485, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.1047, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.7569, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.9091, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.4518, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.4816, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.3510, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.7911, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.4252, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0832, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.6182, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2882, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0442, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0997, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2661, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6707, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2450, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8003, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7773, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.7386, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9397, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0089, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0619, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0191, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2049, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.4621, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8159, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4873, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1099, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9639, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8294, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8914, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4540, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6808, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.0863, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.1537, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1588, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9446, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7758, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4515, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8490, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6779, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5798, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9001, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7120, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.8329, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0827, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0947, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0584, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2415, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2192, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3452, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.3903, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.6349, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8656, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6094, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8626, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5368, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8130, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5552, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.3175, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8214, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0835, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8070, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6032, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4491, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2271, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5360, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8924, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7059, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7720, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2636, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9101, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9748, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0751, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1269, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1261, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7434, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.1693, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9330, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9682, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6535, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0918, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6864, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0531, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3162, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5445, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5775, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1089, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2119, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6942, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6454, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2659, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4687, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8652, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.0791, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.3332, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9031, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5341, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9015, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6830, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0903, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8376, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0      Loss:  tensor(3.0552, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2496, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.6663, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5667, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0904, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9203, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5119, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.7833, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6122, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9181, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7743, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7429, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5853, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3988, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8186, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6803, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2632, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1385, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2747, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0182, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2380, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4181, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8864, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.8906, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7494, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5661, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.5747, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2141, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4944, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2922, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.7923, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.1628, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0993, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9582, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3205, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0423, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5120, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0407, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1675, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0381, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3829, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.8780, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.5767, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2089, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5838, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0503, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6022, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9550, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0539, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.5269, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.7457, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6785, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4242, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2088, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9014, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5832, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9945, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2143, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.0360, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5435, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9461, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.3279, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7714, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.1523, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5926, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2518, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2589, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9973, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(4.0357, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.6202, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0978, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3214, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7507, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7077, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.3016, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3088, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9054, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.7194, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.7557, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3956, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7880, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.3020, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.5218, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0658, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3834, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.9235, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.8148, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.5258, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0307, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1987, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6448, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.4473, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2006, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2306, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.7934, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1113, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.8355, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.3708, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3412, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2112, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.3678, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1059, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.5149, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1463, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.1761, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.3170, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.6590, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.2628, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.8851, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.6544, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.2770, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6307, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4870, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0790, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(3.1181, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.0984, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.9841, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.7700, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.6637, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(2.4977, device='cuda:0')\n",
      "Epoch:  0      Loss:  tensor(1.1741, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6429, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0142, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7857, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6277, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9065, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6639, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4702, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8122, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5315, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8835, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6854, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0420, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2824, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1161, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2637, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.8892, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.9829, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4742, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7433, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6167, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(0.9524, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6892, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8377, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1356, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5490, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.9675, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0996, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4548, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3381, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6043, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.0028, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1      Loss:  tensor(1.9061, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6791, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8295, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2556, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.8219, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.1817, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.4218, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3669, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5138, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.8924, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.0221, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0777, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7937, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5919, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.4161, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.2815, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5441, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.7868, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6832, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7434, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4035, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8031, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7823, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0462, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3463, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7110, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7975, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.8091, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3110, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.2342, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3670, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3997, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2237, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4909, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0968, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3352, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5762, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0907, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.7346, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0518, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2171, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0053, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4853, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0763, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7440, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4573, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0457, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.6719, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4726, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5792, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8726, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.8099, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0159, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4655, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(4.1458, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4126, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.7999, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.7197, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8236, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.3108, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5748, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0980, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1570, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1257, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2992, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6016, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8782, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.3525, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1902, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.7436, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5029, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.3319, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.4524, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7049, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6424, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.5257, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4665, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.7247, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.4445, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.1264, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1474, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.8571, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0705, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(4.8015, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2681, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1871, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.1907, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.8310, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0126, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5691, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1758, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3493, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4895, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2698, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6186, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8376, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1798, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.4802, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1545, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.0304, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6402, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7698, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.0854, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.3241, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1859, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7254, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9168, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7680, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1737, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.9773, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7705, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.1718, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7066, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2168, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5281, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0888, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3705, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.3115, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.6686, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.9068, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4406, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8427, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.9831, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6798, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0036, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6516, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3842, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3650, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4561, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6083, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2242, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6598, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.0454, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5952, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5993, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5199, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6233, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3805, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.0033, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5175, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.2912, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1714, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.3939, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.9917, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.9514, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9441, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(0.4433, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1328, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.3170, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8551, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7745, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8205, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1      Loss:  tensor(1.8450, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2409, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.8995, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9824, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.5803, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6098, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.3729, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6367, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9946, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1334, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9704, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0575, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.0220, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.2272, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9257, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2133, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1165, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5329, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0925, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6163, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8245, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2732, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1871, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6217, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3733, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.2125, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0986, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0797, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6341, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1276, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7576, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7984, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.0804, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6856, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.4051, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6892, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.1166, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6000, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6307, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.9047, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0595, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.8334, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9832, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5823, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.0575, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6947, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.3084, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.1728, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6524, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.4265, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0428, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.0224, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.8845, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.1783, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6518, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8885, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7613, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1284, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6307, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6641, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.7894, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.3657, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1177, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9626, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9950, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.9913, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3793, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.2074, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5557, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9181, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(0.9743, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7133, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.6376, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.8867, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.0734, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.1894, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7733, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0266, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9104, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0100, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(3.0968, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.0695, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.3858, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.1409, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.6873, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.2312, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.9256, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5304, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(1.7008, device='cuda:0')\n",
      "Epoch:  1      Loss:  tensor(2.5661, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0364, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7815, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1156, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2132, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4332, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5561, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0053, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(4.1251, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.9883, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2845, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.5210, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6129, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5654, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.7976, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9100, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.1915, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.3035, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9523, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.8551, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9696, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7063, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.0650, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4064, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9714, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6162, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4085, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3570, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9002, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4962, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0833, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7791, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8444, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3507, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.3162, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6261, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0012, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1233, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4971, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3398, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4537, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5039, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8855, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4402, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2629, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.6297, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6707, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5667, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0164, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.8040, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.1504, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0961, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3866, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7210, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.1528, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8827, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.5621, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8903, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.7254, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.6035, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4426, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.8128, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4735, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2      Loss:  tensor(3.3861, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4775, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.9494, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6052, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7971, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4218, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3684, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.7676, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6695, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4038, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1736, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4822, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1588, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.8637, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.0407, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9819, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(5.1049, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6810, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(4.0878, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6447, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1513, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4958, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4676, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8961, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7385, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.5298, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4106, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0020, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6055, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.5682, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7633, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2631, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.3254, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.1140, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.5352, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0097, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6336, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5320, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6131, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3571, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4374, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5271, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(4.8454, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7828, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4374, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.8638, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3538, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7747, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8264, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4694, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5255, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4342, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3901, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2313, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7503, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2705, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4971, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0284, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4011, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.7663, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.3896, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7892, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.8943, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.0965, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8354, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0283, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2961, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3408, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3193, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4512, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7439, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1778, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3940, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.2342, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6040, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.9860, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3754, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4864, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0506, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2465, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.0292, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.5341, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5531, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.8113, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4334, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3558, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9529, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1222, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3914, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2599, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7496, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.5018, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0945, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.2038, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2994, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.4666, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5478, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7403, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0042, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3262, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6514, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.5774, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4210, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9354, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6655, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.7316, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(5.3052, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6003, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8793, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5678, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9064, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6270, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0268, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.9528, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2640, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8333, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3758, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4786, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4768, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.8631, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.8474, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9154, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6556, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1076, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6974, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.0132, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(4.2969, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8992, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.2975, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3165, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.1926, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.1221, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1687, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4871, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4400, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8792, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5747, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3467, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.1715, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7288, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5342, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3314, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3709, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.0846, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2256, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7007, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4841, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.2978, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.9341, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5502, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3291, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4089, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2      Loss:  tensor(2.2934, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4016, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4542, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.0284, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3845, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3604, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1003, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1904, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1161, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9931, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.1485, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4179, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.3276, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.2960, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6110, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1462, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7778, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8701, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4747, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6963, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3109, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7863, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4525, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.5020, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6313, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6251, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7561, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.6392, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1373, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.6120, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8210, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.1967, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.5534, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6938, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.4617, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.5974, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.9774, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6195, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.0340, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.5013, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8036, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.1995, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8520, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.6886, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8077, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(0.7582, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3322, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.3098, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.4787, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.8158, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.3900, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.4333, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.2783, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(3.3450, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(2.1048, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7404, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.1144, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.1242, device='cuda:0')\n",
      "Epoch:  2      Loss:  tensor(1.7755, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 5\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in train_dataloader:\n",
    "        steps += 1\n",
    "        # Move input and label tensors to the default device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print(\"Epoch: \", epoch, \"     Loss: \", loss)\n",
    "        \n",
    "        '''if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in test_dataloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    \n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(test_dataloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(test_dataloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your network\n",
    "\n",
    "It's good practice to test your trained network on test data, images the network has never seen either in training or validation. This will give you a good estimate for the model's performance on completely new images. Run the test images through the network and measure the accuracy, the same way you did validation. You should be able to reach around 70% accuracy on the test set if the model has been trained well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Testing...\n",
      "Epoch:  1/3..  Train Loss: 2.004..  Test Loss: 1.061..  Test Accuracy: 0.744\n",
      "Training...\n",
      "Testing...\n",
      "Epoch:  2/3..  Train Loss: 1.999..  Test Loss: 0.906..  Test Accuracy: 0.779\n",
      "Training...\n",
      "Testing...\n",
      "Epoch:  3/3..  Train Loss: 1.913..  Test Loss: 0.924..  Test Accuracy: 0.780\n"
     ]
    }
   ],
   "source": [
    "# TODO: Do validation on the test set\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_losses, test_losses = [], []\n",
    "epochs = 3\n",
    "steps = 0\n",
    "\n",
    "\n",
    "# Turn off gradients for validation, saves memory and computations\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    print(\"Training...\")\n",
    "    for images, labels in train_dataloader:\n",
    "        steps += 1\n",
    "        # Move input and label tensors to the default device\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(images)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        print(\"Testing...\")\n",
    "        ## TODO: Implement the validation pass and print out the validation accuracy\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images, labels in valid_dataloader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                log_ps = model.forward(images)\n",
    "                test_loss += criterion(log_ps, labels)\n",
    "                ps = torch.exp(log_ps)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        model.train()\n",
    "        train_losses.append(running_loss/len(train_dataloader))\n",
    "        test_losses.append(test_loss/len(valid_dataloader))\n",
    "        print(\"Epoch:  {}/{}.. \".format(e+1, epochs),\n",
    "              \"Train Loss: {:.3f}.. \".format(running_loss/len(train_dataloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(valid_dataloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(valid_dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the checkpoint\n",
    "\n",
    "Now that your network is trained, save the model so you can load it later for making predictions. You probably want to save other things such as the mapping of classes to indices which you get from one of the image datasets: `image_datasets['train'].class_to_idx`. You can attach this to the model as an attribute which makes inference easier later on.\n",
    "\n",
    "```model.class_to_idx = image_datasets['train'].class_to_idx```\n",
    "\n",
    "Remember that you'll want to completely rebuild the model later so you can use it for inference. Make sure to include any information you need in the checkpoint. If you want to load the model and keep training, you'll want to save the number of epochs as well as the optimizer state, `optimizer.state_dict`. You'll likely want to use this trained model in the next part of the project, so best to save it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save the checkpoint \n",
    "checkpoint = {'input_size': 25088,\n",
    "              'output_size': 102,\n",
    "              'epochs': 2,\n",
    "              'state_dict': model.state_dict(),\n",
    "              'optimizer': optimizer.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the checkpoint\n",
    "\n",
    "At this point it's good to write a function that can load a checkpoint and rebuild the model. That way you can come back to this project and keep working on it without having to retrain the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace)\n",
      "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (14): ReLU(inplace)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): ReLU(inplace)\n",
      "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2)\n",
      "    (3): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.2)\n",
      "    (6): Linear(in_features=512, out_features=102, bias=True)\n",
      "    (7): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a function that loads a checkpoint and rebuilds the model\n",
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    classifier = nn.Sequential(nn.Linear(25088, 2048),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(2048, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(512, 102),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "    model = models.vgg11(pretrained=True)\n",
    "    model.classifier = classifier\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    return model\n",
    "model = load_checkpoint('checkpoint.pth')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for classification\n",
    "\n",
    "Now you'll write a function to use a trained network for inference. That is, you'll pass an image into the network and predict the class of the flower in the image. Write a function called `predict` that takes an image and a model, then returns the top $K$ most likely classes along with the probabilities. It should look like \n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']\n",
    "```\n",
    "\n",
    "First you'll need to handle processing the input image such that it can be used in your network. \n",
    "\n",
    "## Image Preprocessing\n",
    "\n",
    "You'll want to use `PIL` to load the image ([documentation](https://pillow.readthedocs.io/en/latest/reference/Image.html)). It's best to write a function that preprocesses the image so it can be used as input for the model. This function should process the images in the same manner used for training. \n",
    "\n",
    "First, resize the images where the shortest side is 256 pixels, keeping the aspect ratio. This can be done with the [`thumbnail`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) or [`resize`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) methods. Then you'll need to crop out the center 224x224 portion of the image.\n",
    "\n",
    "Color channels of images are typically encoded as integers 0-255, but the model expected floats 0-1. You'll need to convert the values. It's easiest with a Numpy array, which you can get from a PIL image like so `np_image = np.array(pil_image)`.\n",
    "\n",
    "As before, the network expects the images to be normalized in a specific way. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`. You'll want to subtract the means from each color channel, then divide by the standard deviation. \n",
    "\n",
    "And finally, PyTorch expects the color channel to be the first dimension but it's the third dimension in the PIL image and Numpy array. You can reorder dimensions using [`ndarray.transpose`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ndarray.transpose.html). The color channel needs to be first and retain the order of the other two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    # TODO: Process a PIL image for use in a PyTorch model\n",
    "    e1 = image.size[0]\n",
    "    e2 = image.size[1]\n",
    "    if e1 < e2:\n",
    "        h = int(256/e1 * e2)\n",
    "        image = image.resize((256, h))\n",
    "        m = int((h-224)/2)\n",
    "        image = image.crop((16,m,16+224,m+224))\n",
    "    else:\n",
    "        w = int(256/e2 * e1)\n",
    "        image = image.resize((w, 256))\n",
    "        m = int((w-224)/2)\n",
    "        image = image.crop((m,16,m+224,16+224))\n",
    "    np_image = np.array(image)\n",
    "    np_image = np.true_divide(np_image, 255)\n",
    "    np_image -= [0.485, 0.456, 0.406]\n",
    "    np_image /= [0.229, 0.224, 0.225]\n",
    "    np_image = np_image.transpose((2,0,1))\n",
    "    img = torch.FloatTensor([np_image])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your work, the function below converts a PyTorch tensor and displays it in the notebook. If your `process_image` function works, running the output through this function should return the original image (except for the cropped out portions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.view(image.size()[0]*image.size()[1], image.size()[2], image.size()[3])\n",
    "    image = image.numpy()\n",
    "    image = image.transpose((1, 2, 0))\n",
    "    print(image.shape)\n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Prediction\n",
    "\n",
    "Once you can get images in the correct format, it's time to write a function for making predictions with your model. A common practice is to predict the top 5 or so (usually called top-$K$) most probable classes. You'll want to calculate the class probabilities then find the $K$ largest values.\n",
    "\n",
    "To get the top $K$ largest values in a tensor use [`x.topk(k)`](http://pytorch.org/docs/master/torch.html#torch.topk). This method returns both the highest `k` probabilities and the indices of those probabilities corresponding to the classes. You need to convert from these indices to the actual class labels using `class_to_idx` which hopefully you added to the model or from an `ImageFolder` you used to load the data ([see here](#Save-the-checkpoint)). Make sure to invert the dictionary so you get a mapping from index to class as well.\n",
    "\n",
    "Again, this method should take a path to an image and a model checkpoint, then return the probabilities and classes.\n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    img = Image.open(image_path)\n",
    "    img = process_image(img)\n",
    "    \n",
    "    log_ps = model(img)\n",
    "    ps = torch.exp(log_ps)\n",
    "    probs, classIdxes = ps.topk(topk, dim=1)\n",
    "    model.class_to_idx = train_data.class_to_idx\n",
    "    \n",
    "    idx_to_class = {value : key for key,value in model.class_to_idx.items()}\n",
    "    \n",
    "    classes = []\n",
    "    for n in classIdxes[0]:\n",
    "        classes.append(cat_to_name[idx_to_class[int(n)]])\n",
    "    #imshow(img)\n",
    "    probs = probs.detach().numpy()[0]\n",
    "    print(\"Numpy probs: \", probs)\n",
    "    plt.subplot(2, 1, 1) # 1 row, 2 cols, subplot 1\n",
    "    imshow(img, ax=plt.subplot(2,1,1))\n",
    "    plt.subplot(2, 1, 2) # 1 row, 2 cols, subplot 2\n",
    "    plt.bar(classes, probs)\n",
    "    plt.xlabel(\"flower types\")\n",
    "    plt.ylabel(\"probability\")\n",
    "    plt.xticks(rotation = 45)\n",
    "    \n",
    "    #return {\"probs\" : probs, \"classes\": classes}\n",
    "    # TODO: Implement the code to predict the class from an image file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checking\n",
    "\n",
    "Now that you can use a trained model for predictions, check to make sure it makes sense. Even if the testing accuracy is high, it's always good to check that there aren't obvious bugs. Use `matplotlib` to plot the probabilities for the top 5 classes as a bar graph, along with the input image. It should look like this:\n",
    "\n",
    "<img src='assets/inference_example.png' width=300px>\n",
    "\n",
    "You can convert from the class integer encoding to actual flower names with the `cat_to_name.json` file (should have been loaded earlier in the notebook). To show a PyTorch tensor as an image, use the `imshow` function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy probs:  [ 0.84338647  0.10535285  0.04619398  0.00216892  0.00176533]\n",
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0c998834a8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Display an image along with the top 5 classes\n",
    "img_path = \"flowers/test/21/image_06807.jpg\"\n",
    "predict(img_path, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Reminder for Workspace users:** If your network becomes very large when saved as a checkpoint, there might be issues with saving backups in your workspace. You should reduce the size of your hidden layers and train again. \n",
    "    \n",
    "We strongly encourage you to delete these large interim files and directories before navigating to another page or closing the browser tab.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO remove .pth files or move it to a temporary `~/opt` directory in this Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
